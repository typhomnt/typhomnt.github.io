<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | Maxime Garcia</title>
    <link>http://typhomnt.github.io/research/</link>
      <atom:link href="http://typhomnt.github.io/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Wed, 20 Feb 2019 16:22:09 +0100</lastBuildDate>
    <image>
      <url>http://typhomnt.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_box_center_2.png</url>
      <title>Publications</title>
      <link>http://typhomnt.github.io/research/</link>
    </image>
    
    <item>
      <title>Spatial Motion Doodles: Sketching Animation in VR Using Hand Gestures and Laban Motion Analysis</title>
      <link>http://typhomnt.github.io/research/spatial_motion_doodle/</link>
      <pubDate>Wed, 20 Feb 2019 16:22:09 +0100</pubDate>
      <guid>http://typhomnt.github.io/research/spatial_motion_doodle/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://typhomnt.github.io/Images/Animation_Transfer/SMD_Teaser.png&#34; alt=&#34;Teaser&#34;&gt;&lt;/p&gt;
&lt;p&gt;ACM Motion, Interaction and Games 2019 (MIG &amp;lsquo;19)&lt;/p&gt;
&lt;h2 id=&#34;authors-&#34;&gt;Authors&lt;/h2&gt;
&lt;p&gt;Maxime Garcia
(Inria / LJK / Universite Grenoble Alpes)&lt;/p&gt;
&lt;p&gt;Remi Ronfard
(Inria / LJK / Universite Grenoble Alpes)&lt;/p&gt;
&lt;p&gt;Marie-Paule Cani
(Ecole Polythecnique / LIX)&lt;/p&gt;
&lt;h3 id=&#34;abstract-&#34;&gt;Abstract&lt;/h3&gt;
&lt;p&gt;We present a method for easily drafting expressive character animation by playing with instrumented rigid objects. We parse the input 6D trajectories (position and orientation over time) – called spatial motion doodles – into sequences of actions and convert them into detailed character animations using a dataset of parameterized motion clips which are automatically fitted to the doodles in terms of global trajectory and timing. Moreover, we capture the expressiveness of user-manipulation by analyzing Laban effort qualities in the input spatial motion doodles and transferring them to the synthetic motions we generate. We validate the ease of use of our system and the expressiveness of the resulting animations through a series of user studies, showing the interest of our approach for interactive digital storytelling applications dedicated to children and non-expert users, as well as for providing fast drafting tools for animators.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;&lt;iframe width=&#34;838&#34; height=&#34;472&#34; src=&#34;https://www.youtube.com/embed/0xG2dlGg_9M&#34; frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
